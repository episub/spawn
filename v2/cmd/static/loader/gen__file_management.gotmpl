package loader

{{- $fm := .Config.Generate.FileManagement}}

import (
	"bytes"
	"context"
	"crypto/md5"
	"database/sql"
	"fmt"
	"image"
	"io"
	"os"
	"strings"

	"{{.Config.PackageName}}/models"
	"{{.Config.PackageName}}/gnorm/{{$fm.SchemaName}}/file"
	"{{.Config.PackageName}}/gnorm/{{$fm.SchemaName}}/filedata"
	"github.com/episub/spawn/util"
	"github.com/disintegration/imaging"
	"github.com/h2non/filetype"
	svg "github.com/h2non/go-is-svg"
	opentracing "github.com/opentracing/opentracing-go"
	"gocloud.dev/blob"
	_ "gocloud.dev/blob/gcsblob" // Driver for GCP storage

	"image/gif"  // Read gif files
	"image/jpeg" // Read jpeg files
	"image/png"  // Read png files
)

// Storage A storage location for file data
type Storage string

const (
	EnvGCPBucketName = "GCP_BUCKET_NAME"
)

var (
	// StorageDatabase File data stored in our database
	StorageDatabase Storage = "database"
	// StorageGCP File data stored in a GCP bucket
	StorageGCP Storage = "gcp"
)

// FileSizeLimit Limit of file sizes before we try to reduce ourselves
const FileSizeLimit = 2097152

// SupportedImage Image types we support
type SupportedImage string

const (
	// ImagePNG PNG
	ImagePNG SupportedImage = "png"
	// ImageJPEG JPEG
	ImageJPEG SupportedImage = "jpg"
	// ImageGIF GIF
	ImageGIF SupportedImage = "gif"
)

// FileReadSeeker Implements the spawn static.File interface for the purposes of
// delivering files
type FileReadSeeker struct {
	file.Row
	io.ReadSeeker
}

// Name Used for file download
func (f *FileReadSeeker) Name() (string, error) {
	name := f.Row.Name
	if len(name) == 0 {
		name = f.FileID.String()
	}
	if len(f.FileExtension) > 0 {
		name = name + "." + f.FileExtension
	}

	return name, nil
}

// ETag Used to describe if file has changed
func (f *FileReadSeeker) ETag() (string, error) {
	etagRaw := f.Hash
	etag := base64.StdEncoding.EncodeToString([]byte(etagRaw))

	return etag, nil
}

// GetFileReadSeeker Returns a file readseeker suitable for using with Spawn's
// deliver file function
func (l *PostgresLoader) GetFileReadSeeker(
	ctx context.Context,
	fileID uuid.UUID,
) (*FileReadSeeker, error) {
	f, rs, err := l.GetFileData(ctx, fileID)

	frs := FileReadSeeker{Row: f, ReadSeeker: rs}
	return &frs, err
}

// GetFileData Fetches the data for associated file
func (l *PostgresLoader) GetFileData(ctx context.Context, fileID uuid.UUID) (file.Row, io.ReadSeeker, error) {
	span, ctx := opentracing.StartSpanFromContext(ctx, "GetFileData")
	defer span.Finish()

	// Check our storage, as the method to fetch data will depend on that:
	f, err := file.Find(ctx, l.pool, fileID)
	if err != nil {
		return f, nil, sanitiseError(err)
	}

	var data []byte
	switch f.Storage {
	case "gcp":
		print("Fetching via gcp")
		bucket, key, err := bucketKeyFromLocation(ctx, f.Location)
		if err != nil {
			return f, nil, sanitiseError(err)
		}
		data, err := fileDataFromGCP(ctx, bucket, key)
		return f, data, sanitiseError(err)
	default:
		print("Fetching via database")
		err := l.pool.QueryRow("SELECT data FROM {{$fm.SchemaName}}.file_data INNER JOIN {{$fm.SchemaName}}.file ON file.file_data_id_file_data = file_data.file_data_id WHERE file.file_id=$1", fileID).Scan(&data)
		s := bytes.NewReader(data)
		return f, s, sanitiseError(err)
	}
}

// MigrateFile Migrates a file from its current storage to a new storage type
func (l *PostgresLoader) MigrateFile(ctx context.Context, fileID uuid.UUID, migrateTo Storage) error {
	file, err := file.Find(ctx, l.pool, fileID)

	if err != nil {
		return sanitiseError(err)
	}

	// Nothing to do
	if Storage(file.Storage) == migrateTo {
		return nil
	}

	// Grab the file data reader so we can move it
	_, dataReader, err := l.GetFileData(ctx, fileID)

	if err != nil {
		return sanitiseError(err)
	}

	switch migrateTo {
	case StorageGCP:
		err := l.migrateToGCP(ctx, dataReader, file)
		return sanitiseError(err)
	case StorageDatabase:
		err := l.migrateToDatabase(ctx, dataReader, file)
		return sanitiseError(err)
	default:
		return fmt.Errorf("Have not implemented migration to %s", migrateTo)
	}
}

// conditionalCreateFileData Helper function to create file data, or return an existing record if hash matches already
func conditionalCreateFileData(ctx context.Context, db gnorm.DB, data []byte) (uuid.UUID, string, error) {
	var fdid uuid.UUID
	hash := md5.Sum(data)
	strHash := fmt.Sprintf("%x", hash)

	db.QueryRow("SELECT file_data_id FROM {{$fm.SchemaName}}.file_data WHERE hash=$1 LIMIT 1", strHash).Scan(&fdid)

	if fdid == uuid.Nil {
		fileData := filedata.Row{
			Data: data,
			Hash: strHash,
		}
		fileData, err := filedata.Upsert(ctx, db, fileData)

		return fileData.FileDataID, strHash, err
	}

	return fdid, strHash, nil
}

func (l *PostgresLoader) migrateToGCP(ctx context.Context, dataReader io.ReadSeeker, file file.Row) error {
	var prefix string
	if len(file.FileID.String()) >= 3 {
		prefix = file.FileID.String()[:3]
	}

	// Get migrating username from context:
	createdBy, ok := ctx.Value("created_by").(string)
	if !ok {
		return sanitiseError(fmt.Errorf("'created_by' must be set in context for migrateToGCP"))
	}

	fileName := prefix + "/" + file.FileID.String()
	bucketName := os.Getenv(EnvGCPBucketName)
	if len(bucketName) == 0 {
		return fmt.Errorf("%s environment variable cannot be empty", EnvGCPBucketName)
	}

	err := fileDataToGCP(bucketName, fileName, dataReader)
	if err != nil {
		return sanitiseError(err)
	}

	if err != nil {
		return sanitiseError(err)
	}

	// Confirm that the data was saved correctly, just because we're paranoid:
	gcpReader, err := fileDataFromGCP(ctx, bucketName, fileName)

	if err != nil {
		return sanitiseError(err)
	}
	b := new(bytes.Buffer)
	b.ReadFrom(gcpReader)
	readHash := fmt.Sprintf("%x", md5.Sum(b.Bytes()))
	if readHash != file.Hash {
		return sanitiseError(fmt.Errorf("Hash from gcp (%s) did not match expected (%s)", readHash, file.Hash))
	}
	log.Printf("Bytes match")

	// Now update database:
	tx, err := l.pool.Begin()
	if err != nil {
		return rollbackErr(err, tx)
	}

	location := fileName + "@" + bucketName
	_, err = tx.Exec(`
UPDATE {{$fm.SchemaName}}.file
SET
	storage=$1,
	migrate_to=$1,
	file_data_id_file_data=NULL,
	updated=Now(),
	updated_by=(SELECT user_id FROM pm.user WHERE username=$4),
	location=$2
WHERE file_id=$3
`, StorageGCP, location, file.FileID, createdBy)

	if err != nil {
		return rollbackErr(err, tx)
	}

	err = l.deleteFromStorage(ctx, tx, Storage(file.Storage), file)
	if err != nil {
		return rollbackErr(err, tx)
	}

	return sanitiseError(tx.Commit())
}

func (l *PostgresLoader) migrateToDatabase(ctx context.Context, dataReader io.ReadSeeker, file file.Row) error {
	// Get migrating username from context:
	createdBy, ok := ctx.Value("created_by").(string)
	if !ok {
		return sanitiseError(fmt.Errorf("'created_by' must be set in context for migrateToDatabase"))
	}

	// Grab the bytes for file:
	b := new(bytes.Buffer)
	b.ReadFrom(dataReader)
	data := b.Bytes()

	// Add the file to database
	tx, err := l.pool.Begin()
	if err != nil {
		return rollbackErr(err, tx)
	}

	fdid, hash, err := conditionalCreateFileData(ctx, tx, data)
	if err != nil {
		return rollbackErr(err, tx)
	}

	_, err = tx.Exec(`
UPDATE pm.file
SET
	storage=$1,
	migrate_to=$1,
	file_data_id_file_data=$2,
	hash=$3,
	updated=Now(),
	updated_by=(SELECT user_id FROM pm.user WHERE username=$5),
	location=''
WHERE file_id=$4
`, StorageDatabase, fdid, hash, file.FileID, createdBy)

	if err != nil {
		return rollbackErr(err, tx)
	}

	err = tx.Commit()

	if err != nil {
		return rollbackErr(err, tx)
	}

	return sanitiseError(l.deleteFromStorage(ctx, tx, Storage(file.Storage), file))
}

// deleteFromStorage Removes the file from the specified storage.  WARNING:
// this will permanently remove.  Should ideally only be used as part of
// migrate
func (l *PostgresLoader) deleteFromStorage(ctx context.Context, db gnorm.DB, storage Storage, file file.Row) error {
	switch storage {
	case StorageDatabase:
		log.Printf("Deleting (if required) from storage database %s", file.FileDataIDFileData.UUID)
		_, err := db.Exec("DELETE FROM pm.file_data WHERE file_data_id=$1 AND file_data_id NOT IN (SELECT file_data_id_file_data FROM pm.file WHERE file_data_id_file_data IS NOT NULL)", file.FileDataIDFileData.UUID)
		return err
	case StorageGCP:
		bucket, key, err := bucketKeyFromLocation(ctx, file.Location)
		if err != nil {
			return sanitiseError(err)
		}
		return sanitiseError(deleteFromGCP(ctx, bucket, key))
	default:
		return fmt.Errorf("Don't know how to delete from storage %s", storage)
	}
}

func fileDataToGCP(bucketName string, key string, data io.ReadSeeker) error {
	ctx := context.Background()
	bucket, err := blob.OpenBucket(ctx, "gs://"+bucketName)
	if err != nil {
		return err
	}
	defer bucket.Close()

	w, err := bucket.NewWriter(ctx, key, nil)

	if err != nil {
		return err
	}

	_, err = io.Copy(w, data)
	closeErr := w.Close()

	if err != nil {
		return err
	}

	if closeErr != nil {
		return closeErr
	}

	return nil
}

func fileDataFromGCP(ctx context.Context, bucketName string, key string) (io.ReadSeeker, error) {
	bucket, err := blob.OpenBucket(ctx, "gs://"+bucketName)
	if err != nil {
		return nil, err
	}
	defer bucket.Close()

	r, err := bucket.NewReader(ctx, key, nil)
	if err != nil {
		return nil, err
	}

	defer r.Close()
	b := new(bytes.Buffer)
	b.ReadFrom(r)

	s := bytes.NewReader(b.Bytes())
	return s, nil
}

func deleteFromGCP(ctx context.Context, bucketName string, key string) error {
	bucket, err := blob.OpenBucket(ctx, "gs://"+bucketName)
	if err != nil {
		return err
	}
	defer bucket.Close()

	return bucket.Delete(ctx, key)
}

// bucketKeyFromLocation Returns bucket name, key, and error from a storage
// string
func bucketKeyFromLocation(ctx context.Context, location string) (string, string, error) {
	r := strings.Split(location, "@")

	if len(r) != 2 {
		return "", "", fmt.Errorf("Expected length 2, but had %d", len(r))
	}

	return r[1], r[0], nil
}

func resizeImage(data []byte, extension SupportedImage) ([]byte, error) {
	img, _, err := image.Decode(bytes.NewReader(data))
	if err != nil {
		return []byte{}, nil
	}

	// Resize to 1024x1024 bounding box:
	outImg := imaging.Fit(img, 1280, 1280, imaging.Box)

	buf := new(bytes.Buffer)
	switch extension {
	case ImageGIF:
		err = gif.Encode(buf, outImg, nil)
	case ImageJPEG:
		err = jpeg.Encode(buf, outImg, nil)
	case ImagePNG:
		err = png.Encode(buf, outImg)
	}

	return buf.Bytes(), err
}

// updateFileFieldDefault Provides a default update file field function that can
// be used when you don't want to provide your own
func (l *PostgresLoader) updateFileFieldDefault(ctx context.Context, create bool, db gnorm.DB, o *file.Row, field string, v interface{}) (err error) {
	switch field {
	case "id":
		o.FileID, err = util.MustUUID(v)
	case "name":
		var name string
		name, err = util.MustString(v, true)
		if err != nil {
			return
		}

		if len(name) == 0 {
			addFieldGQLError(ctx, "File name cannot be empty", field)
			return
		}

		// We don't want anything after first period:
		parts := strings.Split(name, ".")
		o.Name = parts[0]

		if len(o.FileExtension) == 0 && len(parts) > 1 {
			o.FileExtension = parts[1]
		}
	case "data":
		// Convert from base64 to bytes:
		var b string
		b, err = util.MustString(v, true)
		if err != nil {
			return
		}

		if len(b) == 0 {
			addFieldGQLError(ctx, "Data cannot be empty", field)
			return
		}

		data := []byte(b)

		log.Printf("Data size: %d", len(data))
		// Record file type:
		kind, _ := filetype.Match(data)
		if kind == filetype.Unknown {
			// Check if SVG:
			if svg.Is(data) {
				o.FileType = "image/svg+xml"
				o.FileExtension = "svg"
			}
		} else {
			o.FileType = kind.MIME.Value
			o.FileExtension = kind.Extension

			// If file is too large, we try and resize it if it's a supported image
			// type
			if len(data) > FileSizeLimit {
				switch o.FileExtension {
				case "jpg", "png", "gif":
					data, err = resizeImage(data, SupportedImage(o.FileExtension))
					if err != nil {
						return
					}
				}
			}
		}

		fdid, hash, err := conditionalCreateFileData(ctx, db, data)
		if err != nil {
			return err
		}

		o.Hash = hash
		o.FileDataIDFileData = uuid.NullUUID{UUID: fdid, Valid: true}
	case "description":
		o.Description, err = util.MustString(v, true)
	case "storage":
		o.Storage, err = util.MustString(v, true)
		if err != nil {
			return err
		}
		o.MigrateTo = o.Storage
	default:
		err = fmt.Errorf("Updating '%s' is not enabled, please contact support", field)
	}

	return
}
